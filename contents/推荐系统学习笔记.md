# 推荐系统学习笔记


## 推荐系统的基本定义

### 什么是推荐系统

* 推荐系统能做什么？

推荐系统可以将最终会在用户(User)和物品(Item)之间产生的连接提前找出来

* 推荐系统需要什么？

推荐系统需要已经存在的连接，从已有连接去预测未来的连接

* 推荐系统怎么做？

包括：系统推荐，人工推荐，领域专家推荐


### 是否需要推荐系统

* 产品目的

如果产品的目的是建立起更多的连接，那么推荐系统就有存在的必要

* 现有连接

当连接数较少时，推荐系统存在的必要性也会大打折扣，而决定连接数的关键在于物品的数量

## 推荐系统的问题模式

### 评分预测

机器学习中的回归问题，通过现有的评分数据，对未知数据进行评分预测

通过预测评分与实际评分的均方差来评估模型的好坏

但是这种方式存在其缺陷：

* 数据不易收集，显示的评分是比较难获得的
* 数据质量无法得到保证
* 评分的分布不稳定

### 行为预测

当不能直接有效的获得显式数据，可以借助用户行为产生的各种隐式数据

行为预测分为两类：直接预测行为本身发生的概率，预测物品的相对排序

虽然直接预测用户评分的数据门槛较高，但可以通过行为预测的方式，来判断用户行为的发生概率或可能性，如每个推荐给客户的商品的点击行为预测

### 主要问题

* 冷启动问题

推荐系统是强依赖于数据，数据量越大于推荐系统越有益，那么在一开始，新用户或者不活跃用户，新商品或者展示次数较少的商品，都会因为缺少数据而效果欠佳

解决办法：尽量引入相关数据，并从已有数据中主动学习（半监督学习）

* 探索与利用的问题

在已知的用户喜好基础上，如何进行推荐的问题，通常有三种方式：

1. 根据用户喜好，推荐模型认为其最感兴趣的商品
2. 无视用户喜好，按照其他逻辑进行推荐，如人工推荐等
3. 较大程度上根据其喜好推荐商品，并尝试其他推荐（拓展新的兴趣）


* 安全问题

安全攻击导致的问题主要体现在：

1. 给出不靠谱的推荐结果，影响用户体验与产品形象
2. 导致推荐系统收集到不靠谱的数据，且该影响会长期存在
3. 损害产品的商业利益，导致经济损失

## 推荐系统的认识

### 关键元素

推荐系统的四个关键元素：

* UI & UE
* 数据
* 领域知识
* 算法

四个关键元素的重要性依次递减

### 用户画像

推荐系统通常包括召回和排序两个阶段，用户画像在两个阶段中都能起到自己的作用

* 由于商品数据量大，为一个用户（User）计算每一个商品（Item）的评分的代价太大，所以通常会预先筛选一部分商品，这就需要用到用户画像进行筛选（粗粒度）
* 根据召回过程得到的商品数据，结合用户画像进行细粒度的打分操作，得到商品优先序

用户画像的构建方法

1. 查户口，直接使用原始互数据作为用户画像的内容，除了数据清洗没有做任何的抽象与归纳，对于冷启动等场景是非常有用的
2. 堆数据，堆历史数据做统计工作，从历史行为数据中挖掘出标签，从标签维度上做数据统计
3. 黑盒，通过机器学习方法得到无法直接理解的稠密向量，作用很大

### 构建用户画像

基于内容推荐的推荐系统离不开用户构建的初级画像，这种初级画像一般称作用户画像(User Profile)

**初级画像主要来自于文本内容**，比如

从用户端看

* 注册信息
* 评论与动态信息
* 聊天记录

从物品端也可以构建物品画像(Item Profile) ，并最终作用于用户画像

* 物品标题与描述
* 物品本身内容
* 物品其他属性的文本

从用户与物品的文本信息中构建出基础的用户画像，实施步骤：

1. 把非结构化的文本结构化，保留关键信息
2. 根据用户行为数据将结构化的物品数据结构传递给用户，并于用户自身的结构化信息结合

#### 结构化文本

如何将非结构化的文本内容进行结构化信息提取

* 关键词提取： 基础标签来源，使用 TF-IDF 和 TextRank
* 实物识别： 识别任务、未知和地点等，使用基于词典的方法结合 CRF 模型
* 内容分类：将文本按照分类体系分类，用分类表达较粗粒度的结构化信息
* 文本： 无监督分类
* 主题模型： 聚类


##### 文本结构化算法

* TF-IDF

TF: Term Frequency，词频，待提取的特征词在该文本中出现的次数
IDF: Inverse Document Frequency， 提前统计好的，每个词在多少文本中出现，总共有多少文本，IDF取词出现文档数+1除以总文档数

TF 与 IDF 的乘积作为每个词的权重

* TextRank 算法

* 内容分类

短文本分类的经典算法是SVM，工具上最常用的是Facebook的FastText

* 实体识别

在NLP中被认为是序列标注问题，与分词和词性标注属于同一类问题

1. 分词问题： 对每个字符分类为”词开始“、”词中间“和”词结束“三类之一
2. 词性标注： 对每一个分好的词，分类为其所对应的词性集合之一
3. 实体识别： 对每一个分好的词，识别为定义的命名实体集合之一


对于序列标注问题，通常使用隐马尔科夫模型(HMM)或者条件随机场(CRF)

以实体识别为代表的序列标注问题，工业级别的工具上spaCy 比 NLTK 更有效率

* 聚类

传统聚类方法在文本中的应用，逐渐被主题模型取代，通过一LDA（隐含狄利克雷分布）为代表的主题模型能够更准确抓住主题，且得到软聚类的效果

开源 LDA 训练工具：Gensim, PLDA

#### 标签选择

如何将物品的结构化信息给到用户？

TODO

### 内容推荐

基于内容的推荐的推荐系统是推荐系统的初级阶段，也是必经阶段，因为在此阶段过程中，用户对物品的偏好行为数据还不够，只能单方面的推荐

从另一方面来说，也不并全然是因为处于冷启动阶段，每当系统引入新的物品，都是需要经历内容推荐阶段

基于内容的推荐需要关注四个方面：

1. 抓：获得数据丰富自身内容，增加内容量以及增加分析的维度
2. 洗：数据清洗，提取有效内容
3. 挖：推荐系统不在于使用更加复杂的算法，而是在于对内容的深入挖掘
4. 算：匹配用户的兴趣和物品的属性，计算更加合理的相关性

#### 内容源

抓取数据

#### 内容分析与用户分析

基于内容的推荐，最重要的不是推荐算法，而是内容挖掘与分析

随着内容分析的深入，能够抓住的用户群体就越细致，推荐的转化率就越高

### 协同过滤

当推荐系统经过了基于内容的推荐阶段后，有了一定量级的用户数据，就能构建出用户和物品的关系矩阵

协同过滤包含两个范畴：

* 基于记忆的协同过滤：根据历史喜好，推荐类似物品，或者相同物品推荐给类似的人
* 基于模型的协同过滤：从用户与物品关系矩阵中学习模型

#### 基于用户的协同过滤

1. 准备用户向量，向量的维度是物品的个数，每个维度的值是0或1，代表该用户是否消费国此物品，且向量是稀疏向量
2. 用每个用户的向量，两两计算用户之间的相似度
3. 根据相似用户的行为，为每个用户推荐物品

![](../images/co-filtering-user.png)

计算用户u与物品的匹配分，将u用户与其他用户的相似度作为分母，相似度与其他用户对于该物品的评价的加权和作为分子，计算匹配分

##### 基于用户的协同过滤实操

* 构造矩阵

用户向量矩阵通常来说是稀疏的，对于稀疏矩阵的存储格式包括：

1. CSR：整体编码，数值、列好与行号共同编码
2. COO，三元组存储（行号，列号，数值），且只存储有值得元素

* 相似度计算

当用户向量维度非常大的时候，如何解决？

1. 可以通过向量采样的方式，如从100维的向量中抽取10维，在相似度计算差别不太大情况下是可以接受的
2. 向量化计算，向量计算会远比循环计算快得多

当用户数非常大的时候，两两之间计算代价非常大，如何解决？

1. 通过MapReduce分解任务
2. 考虑其他的协同过滤方式

* 推荐计算

计算推荐匹配分时候，可以注意几个方面：

1. 只有相似用户（设定相似度阈值）喜欢过的物品需要进行计算
2. 拆解成MapReduce任务
	1. 获得该用户的相似用户列表，遍历每个用户喜欢的物品
	2. 将每一个喜欢的物品Map成两条记录发射出去，Map节点的输入输出：（<相似用户ID，物品ID，1>， <相似度>），（<相似度ID，物品ID，0>，<喜欢程度*相似度>）
	3. Reduce 阶段，求和后输出
	4. 最后，相除得到最后的匹配分

	
* 改进

1. 惩罚对热门物品的喜欢程度，热门物品很难反映出用户真实的喜好
2. 增加喜欢程度的时间衰减，一般使用指数函数，指数是一个附属

####  基于物品的协同过滤

基于物品协同过滤方法出现之前，推荐系统最常使用的是基于用户的协同过滤方法，但是基于用户的协同过滤方法会存在一些问题：

* 用户数量大，计算困难
* 用户喜好变化大，兴趣迁移问题难以有效反应
* 数据稀疏，用户之间有共同行为较少，通常针对的是一些热门商品，对发现用户兴趣作用不大

基于物品的协同过滤方法首先需要计算物品之间的相似度，再根据用户消费过、或者正在消费的物品为其推荐相似的物品，那么基于物品的协同过滤方法如何解决上述问题呢？

* 可推荐的物品数量会少于用户数量，所以需要计算相似度的物品数量是有限的
* 物品之间的相似度是比较静态的，相对来说解耦了用户兴趣迁移的问题
* 物品对应的消费者群体的数量大，物品之间的稀疏程度较小

实际上

基于用户的协同过滤 与 基于物品的协同过滤采用的都是全量购买/评分数据的稀疏向量，构建矩阵的话，两种过滤方式对应的矩阵 其实是同一个矩阵的转置矩阵

##### 计算物品相似度

1. 构建物品稀疏向量，向量的维度是用户，每个用户代表向量的一个维度，向量的总维度是总用户数量
2. 维度的取值是用户对该物品的消费结果，可以是结果的布尔值，也可以量化为次数或者评价等
3. 根据余弦相似度计算物品之间的相似度

当然，其中也存在一些改进点：

1. **物品中心化**：将矩阵中的分数，减去物品分数的均值，这样做是为了取出分值当中的极端部分
2. **用户中心化**：将矩阵中的分数，减去对应用户分数的均值，一定程度上保留了喜好，去掉了评价分主观成分

##### 计算推荐结果

* TOP K 推荐

与基于用户的协同过滤方法类似，用相似度加权汇总，要预测用户u对于物品i的分数，取出用户u所有消费并评价过得商品，每一个商品与商品i的相似度乘以商品评分，累加求和并处以相似度之和，得到用户u对于商品i的预测评分

整个过程可以在离线完成，保留分值最高的top k个物品

* 相关推荐 - Slope One 算法

经典的基于物品的推荐模式，去相似度矩阵计算是离线计算更新，无法做到实时，且没有考虑相似度的置信问题，如两个物品都被同一个客户喜欢，且都只有这一个客户喜欢，两个物品的相似度为1，这对结果的影响很大

Slope One 针对这些问题做了优化改进，TODO


### 相似度计算方法

#### 欧氏距离

空间中两个点的距离，计算方式是每个坐标值对应相减后平方处理并求和，最后去方根

欧式距离度量的是空间中两个点的绝对差异，适用于分析用户能力模型之间的差异

#### 余弦相似度

余弦相似度的度量是两个向量之间的夹角，其在度量文本相似度、用户相似度以及物品相似度的时候较为常用

余弦相似度与向量的长度无关，所以需要对向量长度做归一化

由于其与向量长度无关，仅仅只看向量的方向是否一致，所以在某些应用中可能存在问题，如用户A对两部电影的评分是1和2分，用户B对两部电影的评分是3和6分，余弦相似度认为两个用户之间相似度极高，与实际认知不符合

为了改进这个问题，提出了调整后余弦相似度 (Adjusted Cosine Similarity) 方法是先计算向量每个维度上的均值，然后每个向量在各个维度上减去均值后，在计算余弦相似度

#### 皮尔逊相似度

实际上也是一种余弦相似度，不过是先对向量做中心化，向量先各自减去向量的均值后，再做余弦相似度计算

#### 杰卡德相似度

两个集合的交集元素个数在并集中所占的比例，其主要针对的是布尔向量，计算方式是：分子是两个布尔向量的点击计算，得到的就是交集元素个数，分母是两个布尔向量做或运算，再求元素和



### 矩阵分解

基于用户或物品的近邻模型，尽管能够取得不错的效果，但是依然存在其缺陷：

1. 物品之间存在相关性，信息量并不随着向量维度增加而线性增加
2. 矩阵元素稀疏，计算结果不稳定，增减一个向量维度，对于近邻结果的影响可能很大

上述这些问题，在矩阵分解中都能得到很好的解决

矩阵分解，直观上说就是将原来的大矩阵近似分解为两个小矩阵的乘积





