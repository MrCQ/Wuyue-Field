# 机器学习基础课学习笔记

## 频率视角下的机器学习

当重复试验的次数达到无限次时，时间发生的概率就会收敛与其真实的发生概率，那么也就意味着概率是一个确定的值，并不会被单次观察的结果所影响

频率统计的核心在于认定待估计得参数是固定不变的常量，而用来估计参数的数据是随机的变量，参数本身是确定的，而数据是不定的，所以参数估计的不确定性不是来自于参数本身的不确定，而是来源于有限次观察造成的干扰（样本数据的不确定性）

通过样本的分布（采样分布）来得到参数的最优估计，在频率统计中最常采用最优化方法：最大似然估计

最大似然估计：在固定参数的前提下（真实概率P固定），一组数据出现的条件概率最大化

通俗解释最大似然估计，也就是一组数据发生时，其发生概率应当是可能概率中的最大值，如发生概率为P，总计发生了4次，那么这组数据的发生概率应当是P^4，且由于其已发生，概率应当最大为1，P当取1.

统计机器学习：将频率主义中的”参数确定，数据随机“的思路应用在机器学习中。

和参数相关的信息全部来源于数据，输出的则是未知参数唯一的估计结果，这是统计机器学习的核心特征。

## 贝叶斯视角下的机器学习

当独立重复试验不可能完成时，就不能从频率角度来解读概率的理论基础

贝叶斯学派：概率表示的是客观上事件的可信程度

贝叶斯学派与频率学派的不同之处在于：频率统计理论的核心在于认定待估计的参数是固定不变的值，而估计得数据是随机的变量；相反，贝叶斯统计则将待估计的参数视为随机变量，用来估计得数据视作确定的常数

相对于频率主义的最大似然估计，贝叶斯主义在参数估计中倾向于使后验概率最大化，使用最大后验概率估计